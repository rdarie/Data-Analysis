Timer unit: 1e-07 s

Total time: 7.2e-06 s
File: c:\users\peep sheep\nda2\data-analysis\dataAnalysis\helperFunctions\aligned_signal_helpers.py
Function: processAlignQueryArgs at line 23

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    23                                           def processAlignQueryArgs(
    24                                                   namedQueries, alignQuery=None, **kwargs):
    25         1         24.0     24.0     33.3      if (alignQuery is None) or (not len(alignQuery)):
    26                                                   dataQuery = None
    27                                               else:
    28         1         25.0     25.0     34.7          if alignQuery in namedQueries['align']:
    29         1         15.0     15.0     20.8              dataQuery = namedQueries['align'][alignQuery]
    30                                                   else:
    31                                                       dataQuery = alignQuery
    32         1          8.0      8.0     11.1      return dataQuery

Total time: 9.7e-06 s
File: c:\users\peep sheep\nda2\data-analysis\dataAnalysis\helperFunctions\aligned_signal_helpers.py
Function: processUnitQueryArgs at line 76

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    76                                           def processUnitQueryArgs(
    77                                                   namedQueries, scratchFolder,
    78                                                   selector=None, unitQuery=None,
    79                                                   inputBlockName='', **kwargs):
    80         1         18.0     18.0     18.6      if selector is not None:
    81                                                   with open(
    82                                                       os.path.join(
    83                                                           scratchFolder,
    84                                                           selector + '.pickle'),
    85                                                           'rb') as f:
    86                                                       selectorMetadata = pickle.load(f)
    87                                                   unitNames = [
    88                                                       '{}_{}#0'.format(i, inputBlockName)
    89                                                       for i in selectorMetadata['outputFeatures']]
    90                                                   outputQuery = None
    91                                               else:
    92         1         16.0     16.0     16.5          unitNames = None
    93         1         27.0     27.0     27.8          if unitQuery in namedQueries['unit']:
    94         1         22.0     22.0     22.7              outputQuery = namedQueries['unit'][unitQuery]
    95                                                   else:
    96                                                       outputQuery = unitQuery
    97         1         14.0     14.0     14.4      return unitNames, outputQuery

Total time: 1.04e-05 s
File: C:\Users\Peep Sheep\.conda\envs\nda2\lib\copy.py
Function: copy at line 66

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    66                                           def copy(x):
    67                                               """Shallow copy operation on arbitrary Python objects.
    68                                           
    69                                               See the module's __doc__ string for more info.
    70                                               """
    71                                           
    72         1         40.0     40.0     38.5      cls = type(x)
    73                                           
    74         1         35.0     35.0     33.7      copier = _copy_dispatch.get(cls)
    75         1         12.0     12.0     11.5      if copier:
    76         1         17.0     17.0     16.3          return copier(x)
    77                                           
    78                                               try:
    79                                                   issc = issubclass(cls, type)
    80                                               except TypeError: # cls is not a class
    81                                                   issc = False
    82                                               if issc:
    83                                                   # treat it as a regular class:
    84                                                   return _copy_immutable(x)
    85                                           
    86                                               copier = getattr(cls, "__copy__", None)
    87                                               if copier:
    88                                                   return copier(x)
    89                                           
    90                                               reductor = dispatch_table.get(cls)
    91                                               if reductor:
    92                                                   rv = reductor(x)
    93                                               else:
    94                                                   reductor = getattr(x, "__reduce_ex__", None)
    95                                                   if reductor:
    96                                                       rv = reductor(4)
    97                                                   else:
    98                                                       reductor = getattr(x, "__reduce__", None)
    99                                                       if reductor:
   100                                                           rv = reductor()
   101                                                       else:
   102                                                           raise Error("un(shallow)copyable object of type %s" % cls)
   103                                           
   104                                               if isinstance(rv, str):
   105                                                   return x
   106                                               return _reconstruct(x, None, *rv)

Total time: 0.0150419 s
File: c:\users\peep sheep\nda2\data-analysis\dataAnalysis\preproc\ns5.py
Function: listChanNames at line 64

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    64                                           def listChanNames(
    65                                                   dataBlock, chanQuery,
    66                                                   objType=AnalogSignalProxy, condition=None):
    67                                               allChanList = [
    68         1         11.0     11.0      0.0          i.name
    69         1      37897.0  37897.0     25.2          for i in dataBlock.filter(objects=objType)]
    70         1         15.0     15.0      0.0      if condition == 'hasAsigs':
    71                                                   allChanList = [
    72                                                       i
    73                                                       for i in allChanList
    74                                                       if len(dataBlock.filter(objects=objType, name=i)[0].analogsignals)
    75                                                   ]
    76         1         19.0     19.0      0.0      chansToTrigger = pd.DataFrame(
    77         1       1042.0   1042.0      0.7          np.unique(allChanList),
    78         1       8930.0   8930.0      5.9          columns=['chanName'])
    79         1         12.0     12.0      0.0      if chanQuery is not None:
    80         1         22.0     22.0      0.0          chansToTrigger = chansToTrigger.query(
    81         1     102460.0 102460.0     68.1              chanQuery, engine='python')['chanName'].to_list()
    82                                               else:
    83                                                   chansToTrigger = chansToTrigger['chanName'].to_list()
    84         1         11.0     11.0      0.0      return chansToTrigger

Total time: 0.0307897 s
File: c:\users\peep sheep\nda2\data-analysis\dataAnalysis\helperFunctions\aligned_signal_helpers.py
Function: processOutlierTrials at line 57

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    57                                           def processOutlierTrials(
    58                                                   alignSubFolder, prefix,
    59                                                   maskOutlierBlocks=False,
    60                                                   invertOutlierBlocks=False,
    61                                                   window=None,
    62                                                   **kwargs
    63                                                   ):
    64         1         48.0     48.0      0.0      if maskOutlierBlocks:
    65         1         17.0     17.0      0.0          resultPath = os.path.join(
    66         1         10.0     10.0      0.0              alignSubFolder,
    67         1        427.0    427.0      0.1              prefix + '_{}_outliers.h5'.format(window))
    68         1     307354.0 307354.0     99.8          oBlocks = pd.read_hdf(resultPath, 'rejectBlock')
    69         1         30.0     30.0      0.0          if invertOutlierBlocks:
    70                                                       oBlocks = ~oBlocks.astype(np.bool)
    71         1         11.0     11.0      0.0          return oBlocks
    72                                               else:
    73                                                   return None

Total time: 1.03874 s
File: c:\users\peep sheep\nda2\data-analysis\dataAnalysis\preproc\ns5.py
Function: loadObjArrayAnn at line 2903

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
  2903                                           def loadObjArrayAnn(st):
  2904       140       2423.0     17.3      0.0      if 'arrayAnnNames' in st.annotations.keys():
  2905       140       1503.0     10.7      0.0          if isinstance(st.annotations['arrayAnnNames'], str):
  2906                                                       st.annotations['arrayAnnNames'] = [st.annotations['arrayAnnNames']]
  2907       140       1021.0      7.3      0.0          elif isinstance(st.annotations['arrayAnnNames'], tuple):
  2908                                                       st.annotations['arrayAnnNames'] = [i for i in st.annotations['arrayAnnNames']]
  2909                                                   #
  2910      1820      47492.0     26.1      0.5          for key in st.annotations['arrayAnnNames']:
  2911                                                       #  fromRaw, the ann come back as tuple, need to recast
  2912      1680       8807.0      5.2      0.1              try:
  2913      1680     692560.0    412.2      6.7                  if len(st.times) == 1:
  2914                                                               st.annotations[key] = [st.annotations[key]]
  2915      1680      13415.0      8.0      0.1                  st.array_annotations.update(
  2916      1680    4154934.0   2473.2     40.0                      {key: np.asarray(st.annotations[key])})
  2917      1680    5460955.0   3250.6     52.6                  st.annotations[key] = np.asarray(st.annotations[key])
  2918                                                       except Exception:
  2919                                                           traceback.print_exc()
  2920       140       1193.0      8.5      0.0      if hasattr(st, 'waveforms'):
  2921       140        940.0      6.7      0.0          if st.waveforms is None:
  2922                                                       st.waveforms = np.asarray([]).reshape((0, 0, 0))*pq.mV
  2923       140       1400.0     10.0      0.0          elif not len(st.waveforms):
  2924                                                       st.waveforms = np.asarray([]).reshape((0, 0, 0))*pq.mV
  2925       140        720.0      5.1      0.0      return st

Total time: 1.05704 s
File: c:\users\peep sheep\nda2\data-analysis\dataAnalysis\preproc\ns5.py
Function: loadContainerArrayAnn at line 2873

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
  2873                                           def loadContainerArrayAnn(
  2874                                                   container=None, trainList=None
  2875                                                   ):
  2876         1          6.0      6.0      0.0      assert (container is not None) or (trainList is not None)
  2877                                               #
  2878         1          5.0      5.0      0.0      spikesAndEvents = []
  2879         1          4.0      4.0      0.0      returnObj = []
  2880         1          4.0      4.0      0.0      if container is not None:
  2881                                                   #  need the line below! (RD: don't remember why, consider removing)
  2882         1      32645.0  32645.0      0.3          container.create_relationship()
  2883                                                   #
  2884         1          6.0      6.0      0.0          spikesAndEvents += (
  2885         1      36291.0  36291.0      0.3              container.filter(objects=SpikeTrain) +
  2886         1      35711.0  35711.0      0.3              container.filter(objects=Event)
  2887                                                       )
  2888         1          8.0      8.0      0.0          returnObj.append(container)
  2889         1          4.0      4.0      0.0      if trainList is not None:
  2890                                                   spikesAndEvents += trainList
  2891                                                   returnObj.append(trainList)
  2892                                               #
  2893         1          7.0      7.0      0.0      if len(returnObj) == 1:
  2894         1          6.0      6.0      0.0          returnObj = returnObj[0]
  2895                                               else:
  2896                                                   returnObj = tuple(returnObj)
  2897                                               #
  2898       141        951.0      6.7      0.0      for st in spikesAndEvents:
  2899       140   10464794.0  74748.5     99.0          st = loadObjArrayAnn(st)
  2900         1          4.0      4.0      0.0      return returnObj

Total time: 17.9778 s
File: c:\users\peep sheep\nda2\data-analysis\dataAnalysis\preproc\ns5.py
Function: loadWithArrayAnn at line 2928

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
  2928                                           def loadWithArrayAnn(
  2929                                                   dataPath, fromRaw=False,
  2930                                                   mapDF=None, reduceChannelIndexes=False):
  2931         1         12.0     12.0      0.0      if fromRaw:
  2932                                                   reader = nixio_fr.NixIO(filename=dataPath)
  2933                                                   block = readBlockFixNames(
  2934                                                       reader, lazy=False,
  2935                                                       mapDF=mapDF,
  2936                                                       reduceChannelIndexes=reduceChannelIndexes)
  2937                                               else:
  2938         1     107436.0 107436.0      0.1          reader = NixIO(filename=dataPath)
  2939         1  168406633.0 168406633.0     93.7          block = reader.read_block()
  2940                                               
  2941         1   10572211.0 10572211.0      5.9      block = loadContainerArrayAnn(container=block)
  2942                                               
  2943         1          5.0      5.0      0.0      if fromRaw:
  2944                                                   reader.file.close()
  2945                                               else:
  2946         1     692005.0 692005.0      0.4          reader.close()
  2947         1         15.0     15.0      0.0      return block

Total time: 17.9779 s
File: c:\users\peep sheep\nda2\data-analysis\dataAnalysis\preproc\ns5.py
Function: blockFromPath at line 2950

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
  2950                                           def blockFromPath(
  2951                                                   dataPath, lazy=False,
  2952                                                   reduceChannelIndexes=False):
  2953         1         18.0     18.0      0.0      if lazy:
  2954                                                   dataReader = nixio_fr.NixIO(
  2955                                                       filename=dataPath)
  2956                                                   dataBlock = readBlockFixNames(
  2957                                                       dataReader, lazy=lazy,
  2958                                                       reduceChannelIndexes=reduceChannelIndexes)
  2959                                               else:
  2960         1         13.0     13.0      0.0          dataReader = None
  2961         1  179778595.0 179778595.0    100.0          dataBlock = loadWithArrayAnn(dataPath)
  2962         1          6.0      6.0      0.0      return dataReader, dataBlock

Total time: 27.3073 s
File: c:\users\peep sheep\nda2\data-analysis\dataAnalysis\preproc\ns5.py
Function: unitSpikeTrainWaveformsToDF at line 335

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   335                                           def unitSpikeTrainWaveformsToDF(
   336                                                   spikeTrainContainer,
   337                                                   dataQuery=None,
   338                                                   transposeToColumns='bin', fastTranspose=True,
   339                                                   lags=None, decimate=1, rollingWindow=None,
   340                                                   getMetaData=True, verbose=False,
   341                                                   whichSegments=None, windowSize=None, procFun=None):
   342                                               #pdb.set_trace()
   343                                               #  list contains different segments from *one* unit
   344        65       2110.0     32.5      0.0      if isinstance(spikeTrainContainer, ChannelIndex):
   345                                                   assert len(spikeTrainContainer.units) == 0
   346                                                   spiketrains = spikeTrainContainer.units[0].spiketrains
   347        65       1402.0     21.6      0.0      elif isinstance(spikeTrainContainer, Unit):
   348        65       2364.0     36.4      0.0          spiketrains = spikeTrainContainer.spiketrains
   349                                               else:
   350                                                   raise(Exception('not a valid container'))
   351                                               # TODO check if really need to assert uniqueness?
   352        65       1315.0     20.2      0.0      uniqueSpiketrains = []
   353       325       6736.0     20.7      0.0      for st in spiketrains:
   354       260      54422.0    209.3      0.0          if not np.any([st is i for i in uniqueSpiketrains]):
   355       130       2951.0     22.7      0.0              uniqueSpiketrains.append(st)
   356                                               #  subsampling options
   357        65       1442.0     22.2      0.0      decimate = int(decimate)
   358        65       1192.0     18.3      0.0      if whichSegments is not None:
   359                                                   uniqueSpiketrains = [
   360                                                       uniqueSpiketrains[i]
   361                                                       for i in whichSegments
   362                                                   ]
   363                                               #
   364        65       1167.0     18.0      0.0      waveformsList = []
   365                                               #
   366       195      13040.0     66.9      0.0      for segIdx, stIn in enumerate(uniqueSpiketrains):
   367       130       5904.0     45.4      0.0          if verbose:
   368                                                       print('extracting spiketrain from {}'.format(stIn.segment))
   369                                                   #  make sure is not a proxyObj
   370       130       7936.0     61.0      0.0          if isinstance(stIn, SpikeTrainProxy):
   371                                                       st = loadStProxy(stIn)
   372                                                       if (getMetaData) or (dataQuery is not None):
   373                                                           # if there's a query, get metadata temporarily to resolve it
   374                                                           st = loadObjArrayAnn(st)
   375                                                   else:
   376       130       6096.0     46.9      0.0              st = stIn
   377                                                   #  extract bins spaced by decimate argument
   378       130     259008.0   1992.4      0.1          if not st.times.any():
   379                                                       continue
   380       130       5337.0     41.1      0.0          if verbose:
   381                                                       print('extracting wf from {}'.format(stIn.segment))
   382       130       5248.0     40.4      0.0          wf = np.asarray(
   383       130      51181.0    393.7      0.0              np.squeeze(st.waveforms),
   384       130      16946.0    130.4      0.0              dtype='float32')
   385       130       5114.0     39.3      0.0          if wf.ndim == 3:
   386                                                       print('Waveforms from more than one channel!')
   387                                                       if wf.shape[1] > 0:
   388                                                           wf = wf[:, 0, :]
   389       130     547665.0   4212.8      0.2          wfDF = pd.DataFrame(wf)
   390       130       5056.0     38.9      0.0          samplingRate = st.sampling_rate
   391                                                   bins = (
   392       130     104122.0    800.9      0.0              np.asarray(wfDF.columns) / samplingRate -
   393       130     306703.0   2359.3      0.1              st.left_sweep)
   394       130     373429.0   2872.5      0.1          wfDF.columns = np.around(bins.magnitude, decimals=6)
   395       130       4852.0     37.3      0.0          if windowSize is not None:
   396                                                       winMask = (
   397       130     216744.0   1667.3      0.1                  (wfDF.columns >= windowSize[0]) &
   398       130     154436.0   1188.0      0.1                  (wfDF.columns <= windowSize[1]))
   399       130    5893652.0  45335.8      2.2              wfDF = wfDF.loc[:, winMask]
   400       130       4913.0     37.8      0.0          if procFun is not None:
   401                                                       wfDF = procFun(wfDF, st)
   402       130       3822.0     29.4      0.0          idxLabels = ['segment', 'originalIndex', 't']
   403       130   87517653.0 673212.7     32.0          wfDF.loc[:, 't'] = np.asarray(st.times.magnitude)
   404       130       5081.0     39.1      0.0          if (getMetaData) or (dataQuery is not None):
   405                                                       # if there's a query, get metadata temporarily to resolve it
   406       130       3060.0     23.5      0.0              annDict = {}
   407      1690      38901.0     23.0      0.0              for k, values in st.array_annotations.items():
   408      1560      48735.0     31.2      0.0                  if isinstance(getMetaData, Iterable):
   409                                                               # if selecting metadata fields, check that
   410                                                               # the key is in the provided list
   411                                                               if k not in getMetaData:
   412                                                                   continue
   413      1560      48386.0     31.0      0.0                  if isinstance(values[0], str):
   414       390      25667.0     65.8      0.0                      v = np.asarray(values, dtype='str')
   415                                                           else:
   416      1170      35302.0     30.2      0.0                      v = np.asarray(values)
   417      1560      40489.0     26.0      0.0                  annDict.update({k: v})
   418                                                       skipAnnNames = (
   419       130       5224.0     40.2      0.0                  st.annotations['arrayAnnNames'] +
   420                                                           [
   421       130       2651.0     20.4      0.0                      'arrayAnnNames', 'arrayAnnDTypes',
   422       130       2607.0     20.1      0.0                      'nix_name', 'neo_name', 'id',
   423       130       3735.0     28.7      0.0                      'cell_label', 'cluster_label', 'max_on_channel', 'binWidth']
   424                                                           )
   425       130    4741300.0  36471.5      1.7              annDF = pd.DataFrame(annDict)
   426      2340      55704.0     23.8      0.0              for k, value in st.annotations.items():
   427      2210      66439.0     30.1      0.0                  if isinstance(getMetaData, Iterable):
   428                                                               # if selecting metadata fields, check that
   429                                                               # the key is in the provided list
   430                                                               if k not in getMetaData:
   431                                                                   continue
   432      2210      50856.0     23.0      0.0                  if k not in skipAnnNames:
   433                                                               annDF.loc[:, k] = value
   434                                                       #
   435                                                       
   436       130      54497.0    419.2      0.0              annColumns = annDF.columns.to_list()
   437       130       2812.0     21.6      0.0              if getMetaData:
   438       130       3375.0     26.0      0.0                  idxLabels += annColumns
   439       130   13286947.0 102207.3      4.9              spikeDF = annDF.join(wfDF)
   440                                                   else:
   441                                                       spikeDF = wfDF
   442                                                       del wfDF, st
   443       130    4718221.0  36294.0      1.7          spikeDF.loc[:, 'segment'] = segIdx
   444       130    3400116.0  26154.7      1.2          spikeDF.loc[:, 'originalIndex'] = spikeDF.index
   445       130       4382.0     33.7      0.0          spikeDF.columns.name = 'bin'
   446                                                   #
   447       130       2941.0     22.6      0.0          if dataQuery is not None:
   448       130   51373027.0 395177.1     18.8              spikeDF.query(dataQuery, inplace=True)
   449       130      12934.0     99.5      0.0              if not getMetaData:
   450                                                           spikeDF.drop(columns=annColumns, inplace=True)
   451       130      11161.0     85.9      0.0          waveformsList.append(spikeDF)
   452                                                   #pdb.set_trace()
   453                                               #
   454                                               #pdb.set_trace()
   455        65    9849667.0 151533.3      3.6      zeroLagWaveformsDF = pd.concat(waveformsList, axis='index')
   456        65       2517.0     38.7      0.0      if verbose:
   457                                                   prf.print_memory_usage('before transposing waveforms')
   458                                               # TODO implement lags and rolling window addition here
   459        65    2455901.0  37783.1      0.9      metaDF = zeroLagWaveformsDF.loc[:, idxLabels].copy()
   460                                               #pdb.set_trace()
   461        65    2145489.0  33007.5      0.8      zeroLagWaveformsDF.drop(columns=idxLabels, inplace=True)
   462        65       2039.0     31.4      0.0      if lags is None:
   463        65       1336.0     20.6      0.0          lags = [0]
   464        65       1779.0     27.4      0.0      laggedWaveformsDict = {
   465        65       3295.0     50.7      0.0          (spikeTrainContainer.name, k): None for k in lags}
   466       130       2622.0     20.2      0.0      for lag in lags:
   467        65       1497.0     23.0      0.0          if isinstance(lag, int):
   468        65       1448.0     22.3      0.0              shiftedWaveform = zeroLagWaveformsDF.shift(
   469        65    1030230.0  15849.7      0.4                  lag, axis='columns')
   470        65       1766.0     27.2      0.0              if rollingWindow is not None:
   471                                                           halfRollingWin = int(np.ceil(rollingWindow/2))
   472                                                           seekIdx = slice(
   473                                                               halfRollingWin, -halfRollingWin+1, decimate)
   474                                                           # seekIdx = slice(None, None, decimate)
   475                                                           #shiftedWaveform = (
   476                                                           #    shiftedWaveform
   477                                                           #    .rolling(
   478                                                           #        window=rollingWindow, win_type='gaussian',
   479                                                           #        axis='columns', center=True)
   480                                                           #    .mean(std=halfRollingWin))
   481                                                           shiftedWaveform = (
   482                                                               shiftedWaveform
   483                                                               .rolling(
   484                                                                   window=rollingWindow, 
   485                                                                   axis='columns', center=True)
   486                                                               .mean())
   487                                                       else:
   488        65       1183.0     18.2      0.0                  halfRollingWin = 0
   489        65       1815.0     27.9      0.0                  seekIdx = slice(None, None, decimate)
   490                                                           if False:
   491                                                               import matplotlib.pyplot as plt
   492                                                               oldShiftedWaveform = zeroLagWaveformsDF.shift(
   493                                                                   lag, axis='columns')
   494                                                               plt.plot(oldShiftedWaveform.iloc[0, :])
   495                                                               plt.plot(shiftedWaveform.iloc[0, :])
   496                                                               plt.show()
   497                                                       laggedWaveformsDict[
   498                                                           (spikeTrainContainer.name, lag)] = (
   499        65    1141175.0  17556.5      0.4                      shiftedWaveform.iloc[:, seekIdx].copy())
   500        65       2221.0     34.2      0.0          if isinstance(lag, tuple):
   501                                                       halfRollingWin = int(np.ceil(lag[1]/2))
   502                                                       seekIdx = slice(
   503                                                           halfRollingWin, -halfRollingWin+1, decimate)
   504                                                       # seekIdx = slice(None, None, decimate)
   505                                                       shiftedWaveform = (
   506                                                           zeroLagWaveformsDF
   507                                                           .shift(lag[0], axis='columns')
   508                                                           .rolling(
   509                                                               window=lag[1], win_type='gaussian',
   510                                                               axis='columns', center=True)
   511                                                           .mean(std=halfRollingWin))
   512                                                       laggedWaveformsDict[
   513                                                           (spikeTrainContainer.name, lag)] = (
   514                                                               shiftedWaveform.iloc[:, seekIdx].copy())
   515        65       1242.0     19.1      0.0      if transposeToColumns == 'feature':
   516                                                   # stack the bin, name the feature column
   517                                                   # 
   518       130       5291.0     40.7      0.0          for idx, (key, value) in enumerate(laggedWaveformsDict.items()):
   519        65       1176.0     18.1      0.0              if idx == 0:
   520                                                           #pdb.set_trace()
   521        65       1874.0     28.8      0.0                  stackedIndexDF = pd.concat(
   522        65    3143645.0  48363.8      1.2                      [metaDF, value], axis='columns')
   523        65   15415434.0 237160.5      5.6                  stackedIndexDF.set_index(idxLabels, inplace=True)
   524                                                           # don't drop nans for now - might need to keep track of them
   525                                                           # if we need to equalize to another array later
   526        65   49479954.0 761230.1     18.1                  newIndex = stackedIndexDF.stack(dropna=False).index
   527        65       3477.0     53.5      0.0                  idxLabels.append('bin')
   528        65   12157707.0 187041.6      4.5              laggedWaveformsDict[key] = value.stack(dropna=False).to_frame(name=key).reset_index(drop=True)
   529        65       2677.0     41.2      0.0          waveformsDF = pd.concat(
   530        65       2203.0     33.9      0.0              laggedWaveformsDict.values(),
   531        65    2534237.0  38988.3      0.9              axis='columns')
   532        65      33373.0    513.4      0.0          waveformsDF.columns.names = ['feature', 'lag']
   533        65      11767.0    181.0      0.0          waveformsDF.index = newIndex
   534        65       1874.0     28.8      0.0          waveformsDF.columns.name = 'feature'
   535                                               elif transposeToColumns == 'bin':
   536                                                   # add the feature column
   537                                                   waveformsDF = pd.concat(
   538                                                       laggedWaveformsDict,
   539                                                       names=['feature', 'lag', 'originalDummy']).reset_index()
   540                                                   waveformsDF = pd.concat(
   541                                                       [
   542                                                           metaDF.reset_index(drop=True),
   543                                                           waveformsDF.drop(columns='originalDummy')],
   544                                                       axis='columns')
   545                                                   idxLabels += ['feature', 'lag']
   546                                                   waveformsDF.columns.name = 'bin'
   547                                                   waveformsDF.set_index(idxLabels, inplace=True)
   548                                               #
   549        65       1445.0     22.2      0.0      if transposeToColumns != waveformsDF.columns.name:
   550                                                   waveformsDF = transposeSpikeDF(
   551                                                       waveformsDF, transposeToColumns,
   552                                                       fastTranspose=fastTranspose)
   553        65       1048.0     16.1      0.0      return waveformsDF

Total time: 32.3365 s
File: c:\users\peep sheep\nda2\data-analysis\dataAnalysis\preproc\ns5.py
Function: concatenateUnitSpikeTrainWaveformsDF at line 556

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   556                                           def concatenateUnitSpikeTrainWaveformsDF(
   557                                                   units, dataQuery=None,
   558                                                   transposeToColumns='bin', concatOn='index',
   559                                                   fastTranspose=True, getMetaData=True, verbose=False,
   560                                                   addLags=None, decimate=1, rollingWindow=None,
   561                                                   metaDataToCategories=False, windowSize=None,
   562                                                   whichSegments=None, procFun=None):
   563         1          9.0      9.0      0.0      allUnits = []
   564        66        521.0      7.9      0.0      for thisUnit in units:
   565        65       1026.0     15.8      0.0          hasAnySpikes = []
   566       325       3233.0      9.9      0.0          for stIn in thisUnit.spiketrains:
   567       260       2391.0      9.2      0.0              if isinstance(stIn, SpikeTrainProxy):
   568                                                           st = stIn.load(
   569                                                               magnitude_mode='rescaled',
   570                                                               load_waveforms=False)
   571                                                       else:
   572       260       2018.0      7.8      0.0                  st = stIn
   573       260     112871.0    434.1      0.0              hasAnySpikes.append(st.times.any())
   574        65       7417.0    114.1      0.0          if np.any(hasAnySpikes):
   575        65        647.0     10.0      0.0              allUnits.append(thisUnit)
   576         1         14.0     14.0      0.0      waveformsList = []
   577        66       1317.0     20.0      0.0      for idx, thisUnit in enumerate(allUnits):
   578        65        656.0     10.1      0.0          if verbose:
   579                                                       print('concatenating unitDF {}'.format(thisUnit.name))
   580        65        682.0     10.5      0.0          lags = None
   581        65        695.0     10.7      0.0          if addLags is not None:
   582                                                       if thisUnit.name in addLags:
   583                                                           lags = addLags[thisUnit.name]
   584        65       1012.0     15.6      0.0          unitWaveforms = unitSpikeTrainWaveformsToDF(
   585        65        701.0     10.8      0.0              thisUnit, dataQuery=dataQuery,
   586        65        637.0      9.8      0.0              transposeToColumns=transposeToColumns,
   587        65        675.0     10.4      0.0              fastTranspose=fastTranspose, getMetaData=getMetaData,
   588        65        662.0     10.2      0.0              lags=lags, decimate=decimate, rollingWindow=rollingWindow,
   589        65        662.0     10.2      0.0              verbose=verbose, windowSize=windowSize,
   590        65  275740020.0 4242154.2     85.3              whichSegments=whichSegments, procFun=procFun)
   591        65       1535.0     23.6      0.0          if idx == 0:
   592         1        148.0    148.0      0.0              idxLabels = unitWaveforms.index.names
   593        65        936.0     14.4      0.0          if (concatOn == 'columns') and (idx > 0):
   594                                                       # other than first time, we already have the metadata
   595        64    1111616.0  17369.0      0.3              unitWaveforms.reset_index(drop=True, inplace=True)
   596                                                   else:
   597                                                       # first time, or if concatenating indices,
   598                                                       # keep the the metadata
   599         1    2571482.0 2571482.0      0.8              unitWaveforms.reset_index(inplace=True)
   600         1         20.0     20.0      0.0              if metaDataToCategories:
   601                                                           # convert metadata to categoricals to free memory
   602                                                           #
   603                                                           unitWaveforms[idxLabels] = (
   604                                                               unitWaveforms[idxLabels]
   605                                                               .astype('category')
   606                                                               )
   607        65       1514.0     23.3      0.0          waveformsList.append(unitWaveforms)
   608        65        723.0     11.1      0.0          del unitWaveforms
   609        65        684.0     10.5      0.0          if verbose:
   610                                                       print('memory usage: {:.1f} MB'.format(prf.memory_usage_psutil()))
   611         1          8.0      8.0      0.0      if verbose:
   612                                                   print(
   613                                                       'about to join all, memory usage: {:.1f} MB'
   614                                                       .format(prf.memory_usage_psutil()))
   615                                               #  if concatenating indexes, reset the index of the result
   616                                               #  ignoreIndex = (concatOn == 'index')
   617         1         21.0     21.0      0.0      allWaveforms = pd.concat(
   618         1    3645565.0 3645565.0      1.1          waveformsList, axis=concatOn,
   619                                                   # ignore_index=ignoreIndex
   620                                                   )
   621         1     349177.0 349177.0      0.1      del waveformsList
   622         1         21.0     21.0      0.0      if verbose:
   623                                                   print(
   624                                                       'finished concatenating, memory usage: {:.1f} MB'
   625                                                       .format(prf.memory_usage_psutil()))
   626         1         10.0     10.0      0.0      try:
   627         1   13723693.0 13723693.0      4.2          allWaveforms.set_index(idxLabels, inplace=True)
   628         1         47.0     47.0      0.0          allWaveforms.sort_index(
   629         1         14.0     14.0      0.0              level=['segment', 'originalIndex', 't'],
   630         1   24988087.0 24988087.0      7.7              axis='index', inplace=True, kind='mergesort')
   631         1         36.0     36.0      0.0          allWaveforms.sort_index(
   632         1    1091359.0 1091359.0      0.3              axis='columns', inplace=True, kind='mergesort')
   633                                               except:
   634                                                   pdb.set_trace()
   635         1         17.0     17.0      0.0      return allWaveforms

Total time: 32.7558 s
File: c:\users\peep sheep\nda2\data-analysis\dataAnalysis\preproc\ns5.py
Function: alignedAsigsToDF at line 638

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   638                                           def alignedAsigsToDF(
   639                                                   dataBlock, unitNames=None,
   640                                                   unitQuery=None, dataQuery=None,
   641                                                   collapseSizes=False, verbose=False,
   642                                                   duplicateControlsByProgram=False,
   643                                                   amplitudeColumn='amplitude',
   644                                                   programColumn='program',
   645                                                   electrodeColumn='electrode',
   646                                                   transposeToColumns='bin', concatOn='index', fastTranspose=True,
   647                                                   addLags=None, decimate=1, rollingWindow=None,
   648                                                   whichSegments=None, windowSize=None,
   649                                                   getMetaData=True, metaDataToCategories=True,
   650                                                   outlierTrials=None, invertOutlierMask=False,
   651                                                   makeControlProgram=False, removeFuzzyName=False, procFun=None):
   652                                               #  channels to trigger
   653         1         17.0     17.0      0.0      if unitNames is None:
   654         1     150651.0 150651.0      0.0          unitNames = listChanNames(dataBlock, unitQuery, objType=Unit)
   655         1         16.0     16.0      0.0      allUnits = []
   656        66       1536.0     23.3      0.0      for uName in unitNames:
   657        65    2965109.0  45617.1      0.9          allUnits += dataBlock.filter(objects=Unit, name=uName)
   658         1         17.0     17.0      0.0      allWaveforms = concatenateUnitSpikeTrainWaveformsDF(
   659         1         15.0     15.0      0.0          allUnits, dataQuery=dataQuery,
   660         1         13.0     13.0      0.0          transposeToColumns=transposeToColumns, concatOn=concatOn,
   661         1         14.0     14.0      0.0          fastTranspose=fastTranspose,
   662         1         14.0     14.0      0.0          addLags=addLags, decimate=decimate, rollingWindow=rollingWindow,
   663         1         13.0     13.0      0.0          verbose=verbose, whichSegments=whichSegments,
   664         1         15.0     15.0      0.0          windowSize=windowSize, procFun=procFun,
   665         1  323396878.0 323396878.0     98.7          getMetaData=getMetaData, metaDataToCategories=metaDataToCategories)
   666                                               #
   667         1         29.0     29.0      0.0      manipulateIndex = np.any(
   668                                                   [
   669         1         15.0     15.0      0.0              collapseSizes, duplicateControlsByProgram,
   670         1        382.0    382.0      0.0              makeControlProgram, removeFuzzyName
   671                                                       ])
   672         1         18.0     18.0      0.0      if outlierTrials is not None:
   673                                                   def rejectionLookup(entry):
   674                                                       key = []
   675                                                       for subKey in outlierTrials.index.names:
   676                                                           keyIdx = allWaveforms.index.names.index(subKey)
   677                                                           key.append(entry[keyIdx])
   678                                                       # print(key)
   679                                                       # outlierTrials.iloc[1, :]
   680                                                       # allWaveforms.iloc[1, :]
   681                                                       return outlierTrials[tuple(key)]
   682                                                   #
   683                                                   outlierMask = np.asarray(
   684                                                       allWaveforms.index.map(rejectionLookup),
   685                                                       dtype=np.bool)
   686                                                   if invertOutlierMask:
   687                                                       outlierMask = ~outlierMask
   688                                                   allWaveforms = allWaveforms.loc[~outlierMask, :]
   689         1         20.0     20.0      0.0      if manipulateIndex and getMetaData:
   690                                                   idxLabels = allWaveforms.index.names
   691                                                   allWaveforms.reset_index(inplace=True)
   692                                                   # 
   693                                                   if collapseSizes:
   694                                                       try:
   695                                                           allWaveforms.loc[allWaveforms['pedalSizeCat'] == 'XL', 'pedalSizeCat'] = 'L'
   696                                                           allWaveforms.loc[allWaveforms['pedalSizeCat'] == 'XS', 'pedalSizeCat'] = 'S'
   697                                                       except Exception:
   698                                                           traceback.print_exc()
   699                                                   if makeControlProgram:
   700                                                       try:
   701                                                           allWaveforms.loc[allWaveforms[amplitudeColumn] == 0, programColumn] = 999
   702                                                           allWaveforms.loc[allWaveforms[amplitudeColumn] == 0, electrodeColumn] = 'control'
   703                                                       except Exception:
   704                                                           traceback.print_exc()
   705                                                   if duplicateControlsByProgram:
   706                                                       #
   707                                                       noStimWaveforms = (
   708                                                           allWaveforms
   709                                                           .loc[allWaveforms[amplitudeColumn] == 0, :]
   710                                                           )
   711                                                       stimWaveforms = (
   712                                                           allWaveforms
   713                                                           .loc[allWaveforms[amplitudeColumn] != 0, :]
   714                                                           .copy()
   715                                                           )
   716                                                       uniqProgs = stimWaveforms[programColumn].unique()
   717                                                       progElecLookup = {}
   718                                                       for progIdx in uniqProgs:
   719                                                           theseStimDF = stimWaveforms.loc[
   720                                                               stimWaveforms[programColumn] == progIdx,
   721                                                               electrodeColumn]
   722                                                           elecIdx = theseStimDF.iloc[0]
   723                                                           progElecLookup.update({progIdx: elecIdx})
   724                                                       #
   725                                                       if makeControlProgram:
   726                                                           uniqProgs = np.append(uniqProgs, 999)
   727                                                           progElecLookup.update({999: 'control'})
   728                                                       #
   729                                                       for progIdx in uniqProgs:
   730                                                           dummyWaveforms = noStimWaveforms.copy()
   731                                                           dummyWaveforms.loc[:, programColumn] = progIdx
   732                                                           dummyWaveforms.loc[:, electrodeColumn] = progElecLookup[progIdx]
   733                                                           stimWaveforms = pd.concat([stimWaveforms, dummyWaveforms])
   734                                                       stimWaveforms.reset_index(drop=True, inplace=True)
   735                                                       allWaveforms = stimWaveforms
   736                                                   #
   737                                                   if removeFuzzyName:
   738                                                       fuzzyNamesBase = [
   739                                                           i.replace('Fuzzy', '')
   740                                                           for i in idxLabels
   741                                                           if 'Fuzzy' in i]
   742                                                       colRenamer = {n + 'Fuzzy': n for n in fuzzyNamesBase}
   743                                                       fuzzyNamesBasePresent = [
   744                                                           i
   745                                                           for i in fuzzyNamesBase
   746                                                           if i in allWaveforms.columns]
   747                                                       allWaveforms.drop(columns=fuzzyNamesBasePresent, inplace=True)
   748                                                       allWaveforms.rename(columns=colRenamer, inplace=True)
   749                                                       idxLabels = np.unique(
   750                                                           [i.replace('Fuzzy', '') for i in idxLabels])
   751                                                   #
   752                                                   allWaveforms.set_index(
   753                                                       list(idxLabels),
   754                                                       inplace=True)
   755                                                   if isinstance(allWaveforms.columns, pd.MultiIndex):
   756                                                       allWaveforms.columns = allWaveforms.columns.remove_unused_levels()
   757                                               #
   758         1         18.0     18.0      0.0      if transposeToColumns == 'feature':
   759         1       5280.0   5280.0      0.0          zipNames = zip(pd.unique(allWaveforms.columns.get_level_values('feature')).tolist(), unitNames)
   760         1         19.0     19.0      0.0          try:
   761         1        474.0    474.0      0.0              assert np.all([i == j for i, j in zipNames]), 'columns out of requested order!'
   762                                                   except Exception:
   763                                                       traceback.print_exc()
   764                                                       allWaveforms.reindex(columns=unitNames)
   765         1         31.0     31.0      0.0      if isinstance(allWaveforms.columns, pd.MultiIndex):
   766         1       8189.0   8189.0      0.0          allWaveforms.columns = allWaveforms.columns.remove_unused_levels()
   767         1         22.0     22.0      0.0      allWaveforms.sort_index(
   768         1    1028851.0 1028851.0      0.3          axis='columns', inplace=True, kind='mergesort')
   769         1         26.0     26.0      0.0      return allWaveforms

Total time: 912.319 s
File: ./exportForDeepSpine.py
Function: exportForDeepSpineWrapper at line 49

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    49                                           def exportForDeepSpineWrapper():
    50         1      37932.0  37932.0      0.0      sns.set()
    51         1       5497.0   5497.0      0.0      sns.set_color_codes("dark")
    52         1       3709.0   3709.0      0.0      sns.set_context("talk")
    53         1       9908.0   9908.0      0.0      sns.set_style("whitegrid")
    54                                               #
    55         1         80.0     80.0      0.0      analysisSubFolder = os.path.join(
    56         1        575.0    575.0      0.0          scratchFolder, arguments['analysisName']
    57                                                   )
    58         1         63.0     63.0      0.0      alignSubFolder = os.path.join(
    59         1        426.0    426.0      0.0          analysisSubFolder, arguments['alignFolderName']
    60                                                   )
    61         1        410.0    410.0      0.0      calcSubFolder = os.path.join(alignSubFolder, 'dataframes')
    62         1       1465.0   1465.0      0.0      if not os.path.exists(calcSubFolder):
    63                                                   os.makedirs(calcSubFolder, exist_ok=True)
    64                                           
    65         1         66.0     66.0      0.0      if arguments['processAll']:
    66         1         63.0     63.0      0.0          prefix = assembledName
    67                                               else:
    68                                                   prefix = ns5FileName
    69         1         67.0     67.0      0.0      alignedAsigsKWargs['dataQuery'] = ash.processAlignQueryArgs(
    70         1        293.0    293.0      0.0          namedQueries, **arguments)
    71                                               alignedAsigsKWargs['unitNames'], alignedAsigsKWargs['unitQuery'] = (
    72         1         61.0     61.0      0.0          ash.processUnitQueryArgs(
    73         1        380.0    380.0      0.0              namedQueries, analysisSubFolder, **arguments))
    74         1         59.0     59.0      0.0      outlierTrialNames = ash.processOutlierTrials(
    75         1     308276.0 308276.0      0.0          calcSubFolder, prefix, **arguments)
    76                                           
    77         1         79.0     79.0      0.0      if arguments['window'] == 'XS':
    78         1         61.0     61.0      0.0          cropWindow = (-100e-3, 400e-3)
    79                                               elif arguments['window'] == 'XSPre':
    80                                                   cropWindow = (-600e-3, -100e-3)
    81                                           
    82         1         73.0     73.0      0.0      alignedAsigsKWargs.update(dict(
    83         1         57.0     57.0      0.0          duplicateControlsByProgram=False,
    84         1         58.0     58.0      0.0          makeControlProgram=False,
    85         1         55.0     55.0      0.0          metaDataToCategories=False,
    86         1         99.0     99.0      0.0          removeFuzzyName=False,
    87         1         58.0     58.0      0.0          decimate=1,
    88         1         57.0     57.0      0.0          windowSize=cropWindow,
    89         1        135.0    135.0      0.0          transposeToColumns='feature', concatOn='columns',))
    90                                               #
    91         1         79.0     79.0      0.0      triggeredPath = os.path.join(
    92         1         58.0     58.0      0.0          alignSubFolder,
    93         1         59.0     59.0      0.0          prefix + '_{}_{}.nix'.format(
    94         1        620.0    620.0      0.0              arguments['inputBlockName'], arguments['window']))
    95         1         65.0     65.0      0.0      outputPath = os.path.join(
    96         1         59.0     59.0      0.0          alignSubFolder,
    97         1         61.0     61.0      0.0          prefix + '_{}_{}_export.h5'.format(
    98         1        446.0    446.0      0.0              arguments['inputBlockName'], arguments['window']))
    99         1       1297.0   1297.0      0.0      print('loading {}'.format(triggeredPath))
   100                                           
   101         1         74.0     74.0      0.0      dataReader, dataBlock = ns5.blockFromPath(
   102         1  179778833.0 179778833.0      2.0          triggeredPath, lazy=arguments['lazy'])
   103         1         29.0     29.0      0.0      asigWide = ns5.alignedAsigsToDF(
   104         1  327562187.0 327562187.0      3.6          dataBlock, **alignedAsigsKWargs)
   105                                               # asigWide is a dataframe
   106         1    2370307.0 2370307.0      0.0      metaData = asigWide.index.to_frame()
   107         1     600875.0 600875.0      0.0      elecNames = metaData['electrode'].unique()
   108                                           
   109                                               # elecRegex = r'([\-]?[\S\s]*\d)([\+]?[\S\s]*\d)'
   110                                               # elecRegex = r'((?:\-|\+)(?:(?:rostral|caudal)\S_\S\S\S)*)*'
   111                                           
   112         1         29.0     29.0      0.0      elecRegex = r'((?:\-|\+)(?:(?:rostral|caudal)\S_\S\S\S)*)'
   113         1         19.0     19.0      0.0      chanRegex = r'((?:rostral|caudal)\S_\S\S\S)'
   114         1         19.0     19.0      0.0      elecChanNames = []
   115         1         19.0     19.0      0.0      stimConfigLookup = {}
   116        11        271.0     24.6      0.0      for comboName in elecNames:
   117        10       9901.0    990.1      0.0          matches = re.findall(elecRegex, comboName)
   118        10        193.0     19.3      0.0          if matches:
   119        10       2232.0    223.2      0.0              print(comboName)
   120        10        220.0     22.0      0.0              thisLookup = {'cathodes': [], 'anodes': []}
   121        20        383.0     19.1      0.0              for matchGroup in matches:
   122        10       1744.0    174.4      0.0                  print('\t' + matchGroup)
   123        10        213.0     21.3      0.0                  if len(matchGroup):
   124        10       6737.0    673.7      0.0                      theseChanNames = re.findall(chanRegex, matchGroup)
   125        10        192.0     19.2      0.0                      if theseChanNames:
   126        21        400.0     19.0      0.0                          for chanName in theseChanNames:
   127        11        226.0     20.5      0.0                              if chanName not in elecChanNames:
   128        11        219.0     19.9      0.0                                  elecChanNames.append(chanName)
   129        10        194.0     19.4      0.0                          if '-' in matchGroup:
   130        21        400.0     19.0      0.0                              for chanName in theseChanNames:
   131        11        216.0     19.6      0.0                                  if chanName not in thisLookup['cathodes']:
   132        11        220.0     20.0      0.0                                      thisLookup['cathodes'].append(chanName)
   133        10        190.0     19.0      0.0                          if '+' in matchGroup:
   134                                                                       for chanName in theseChanNames:
   135                                                                           if chanName not in thisLookup['anodes']:
   136                                                                               thisLookup['anodes'].append(chanName)
   137        10        201.0     20.1      0.0              stimConfigLookup[comboName] = thisLookup
   138                                           
   139         1         37.0     37.0      0.0      eesColumns = pd.MultiIndex.from_tuples(
   140         1         75.0     75.0      0.0          [(eCN, 'amplitude') for eCN in sorted(elecChanNames)],
   141         1      17256.0  17256.0      0.0          names=['object', 'property']
   142                                                   )
   143                                               #
   144         1     509115.0 509115.0      0.0      trialIndex = pd.Index(np.unique(metaData['bin']))
   145         1         46.0     46.0      0.0      trialColumns = pd.MultiIndex.from_tuples(
   146                                                   [
   147         1         20.0     20.0      0.0              ('hip_flexion_r', 'angle'), ('knee_angle_r', 'angle'),
   148         1         23.0     23.0      0.0              ('hip_flexion_l', 'angle'), ('knee_angle_l', 'angle'),
   149         1      17620.0  17620.0      0.0          ], names=['object', 'property'])
   150                                               #
   151                                               # manualPeriod = 0.01
   152                                               # manualStimTimes = np.arange(0, 0.3 + manualPeriod, manualPeriod)
   153                                               # manualEESWaveform = trialIndex.isin(manualStimTimes)
   154                                               # print(metaData.reset_index(drop=True))
   155                                               # print(metaData['electrode'])
   156         1         36.0     36.0      0.0      nullKinematics = pd.DataFrame(
   157         1       2407.0   2407.0      0.0          0, index=trialIndex, columns=trialColumns)
   158         1         25.0     25.0      0.0      kinKey = '/sling/kinematics'
   159         1     102518.0 102518.0      0.0      with pd.HDFStore(outputPath) as store:
   160         1     278730.0 278730.0      0.0          nullKinematics.to_hdf(store, kinKey)
   161         1         29.0     29.0      0.0      eesIdx = 0
   162                                           
   163       281    6919380.0  24624.1      0.1      for stimName, stimGroup in asigWide.groupby(['electrode', 'RateInHz', 'nominalCurrent']):
   164       280    7909629.0  28248.7      0.1          if stimGroup.groupby(['segment', 't']).ngroups < 5:
   165                                                       continue
   166       280     193628.0    691.5      0.0          print(stimName)
   167      3080   62971293.0  20445.2      0.7          for trialIdx, (trialName, trialGroup) in enumerate(stimGroup.groupby(['segment', 't'])):
   168      2800     205821.0     73.5      0.0              stimKey = '/sling/sheep/spindle_0/biophysical/ees_{:0>3}/stim'.format(eesIdx)
   169      2800     176092.0     62.9      0.0              eesPeriod = stimName[1] ** -1
   170      2800     302796.0    108.1      0.0              stimTimes = np.arange(0, 0.3, eesPeriod)
   171      2800    1159319.0    414.0      0.0              EESWaveform = np.zeros_like(trialIndex)
   172                                                       # TODO replace this with the hf.findClosestTimes implementation
   173      2800     104156.0     37.2      0.0              if not arguments['noStim']:
   174     44100    1410811.0     32.0      0.0                  for stimTime in stimTimes:
   175     41300  147296645.0   3566.5      1.6                      closestIndexTime = np.argmin(np.abs((trialIndex - stimTime)))
   176     41300    1593395.0     38.6      0.0                      EESWaveform[closestIndexTime] = 1
   177      2800      83059.0     29.7      0.0              eesIdx += 1
   178      2800    9346429.0   3338.0      0.1              theseResults = pd.DataFrame(0, index=trialIndex, columns=eesColumns)
   179      5880     250038.0     42.5      0.0              for cathodeName in stimConfigLookup[stimName[0]]['cathodes']:
   180      3080   48820517.0  15850.8      0.5                  theseResults.loc[:, (cathodeName, 'amplitude')] = EESWaveform * stimName[2] / len(stimConfigLookup[stimName[0]]['cathodes'])
   181      2800     106579.0     38.1      0.0              for anodeName in stimConfigLookup[stimName[0]]['anodes']:
   182                                                           theseResults.loc[:, (anodeName, 'amplitude')] = EESWaveform * stimName[2] * (-1) / len(stimConfigLookup[stimName[0]]['anodes'])
   183    184800    9083011.0     49.2      0.1              for cName, lag in trialGroup.columns:
   184    182000    5173024.0     28.4      0.1                  if 'EmgEnv' in cName:
   185     36400    1373794.0     37.7      0.0                      mName = cName.split('EmgEnv')[0]
   186     36400 1226398891.0  33692.3     13.4                      theseResults.loc[:, (mName, 'emg_env')] = trialGroup[cName].to_numpy()
   187    145600    3692301.0     25.4      0.0                  elif 'Emg' in cName:
   188     36400    1344571.0     36.9      0.0                      mName = cName.split('Emg')[0]
   189     36400 1228237166.0  33742.8     13.5                      theseResults.loc[:, (mName, 'emg')] = trialGroup[cName].to_numpy()
   190    109200    2930451.0     26.8      0.0                  elif ('caudal' in cName) or ('rostral' in cName):
   191                                                               lfpName = cName[:-4]
   192                                                               theseResults.loc[:, (lfpName, 'lfp')] = trialGroup[cName].to_numpy()
   193    109200    2828420.0     25.9      0.0                  elif ('Acc' in cName):
   194    109200    4124831.0     37.8      0.0                      nameParts = cName.split('Acc')
   195    109200    2837014.0     26.0      0.0                      mName = nameParts[0]
   196    109200 3867402300.0  35415.8     42.4                      theseResults.loc[:, (mName, 'acc_{}'.format(nameParts[1][0].lower()))] = trialGroup[cName].to_numpy()
   197      2800  336038553.0 120013.8      3.7              with pd.HDFStore(outputPath) as store:
   198      2800 1563224722.0 558294.5     17.1                  theseResults.to_hdf(store, stimKey)
   199                                                           thisMetadata = {
   200      2800     137284.0     49.0      0.0                      'globalIdx': eesIdx, 'combinationIdx': trialIdx,
   201      2800     100210.0     35.8      0.0                      'electrode': stimName[0], 'RateInHz': stimName[1],
   202      2800     111220.0     39.7      0.0                      'amplitude': stimName[2]}
   203      2800     109960.0     39.3      0.0                  if arguments['maskOutlierBlocks']:
   204      2800    7974347.0   2848.0      0.1                      thisMetadata['outlierTrial'] = outlierTrialNames.loc[trialName]
   205      2800   59580700.0  21278.8      0.7                  store.get_storer(stimKey).attrs.metadata = thisMetadata
   206                                           
   207         1         51.0     51.0      0.0      if arguments['lazy']:
   208                                                   dataReader.file.close()
   209         1         23.0     23.0      0.0      return

