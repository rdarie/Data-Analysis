Timer unit: 1e-07 s

Total time: 51.7398 s
File: C\../../analysis-code/assembleExperimentData.py
Function: assembleExperimentDataWrapper at line 33

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    33                                           @profile
    34                                           def assembleExperimentDataWrapper():
    35         1       7328.0   7328.0      0.0      from currentExperiment import parseAnalysisOptions
    36         1      94390.0  94390.0      0.0      from docopt import docopt
    37         1      28266.0  28266.0      0.0      arguments = {arg.lstrip('-'): value for arg, value in docopt(__doc__).items()}
    38         1         20.0     20.0      0.0      expOpts, allOpts = parseAnalysisOptions(
    39         1         24.0     24.0      0.0          int(arguments['blockIdx']),
    40         1   12703307.0 12703307.0      2.5          arguments['exp'])
    41         1        142.0    142.0      0.0      globals().update(expOpts)
    42         1        170.0    170.0      0.0      globals().update(allOpts)
    43                                           
    44         1         47.0     47.0      0.0      applyTimeOffset = False
    45         1         45.0     45.0      0.0      suffixList = []
    46         1         56.0     56.0      0.0      if arguments['processAsigs']:
    47         1         50.0     50.0      0.0          suffixList.append('_analyze')
    48         1         48.0     48.0      0.0      if arguments['processRasters']:
    49         1         47.0     47.0      0.0          suffixList.append('_binarized')
    50                                           
    51         3         88.0     29.3      0.0      for suffix in suffixList:
    52         2       1779.0    889.5      0.0          print('assembling {}'.format(suffix))
    53         2         86.0     43.0      0.0          experimentDataPath = os.path.join(
    54         2         74.0     37.0      0.0              scratchFolder, arguments['analysisName'],
    55                                                       assembledName +
    56         2        881.0    440.5      0.0              suffix + '.nix')
    57                                                   #print(experimentDataPath)
    58                                                   #pdb.set_trace()
    59                                                   # Scan ahead through all files and ensure that
    60                                                   # spikeTrains and units are present across all assembled files
    61         2         77.0     38.5      0.0          masterChanDF = pd.DataFrame([], columns=[
    62         2         61.0     30.5      0.0              'index', 'channel_names', 'channel_ids',
    63         2     169990.0  84995.0      0.0              'hasUnits', 'hasAsigs'
    64                                                       ])
    65         2     112966.0  56483.0      0.0          masterUnitDF = pd.DataFrame([], columns=['parentChanName'])
    66         2         69.0     34.5      0.0          blocksCache = {}
    67         8        197.0     24.6      0.0          for idx, trialBasePath in enumerate(trialsToAssemble):
    68                                                       trialDataPath = (
    69         6        108.0     18.0      0.0                  trialBasePath
    70         6        194.0     32.3      0.0                  .format(arguments['analysisName'])
    71         6        199.0     33.2      0.0                  .replace('.nix', '{}.nix'.format(suffix))
    72                                                           )
    73                                                       # dataReader, dataBlock = preproc.blockFromPath(
    74                                                       #     trialDataPath, lazy=True, reduceChannelIndexes=True)
    75         6        168.0     28.0      0.0              dataBlock = preproc.loadWithArrayAnn(
    76         6  174288773.0 29048128.8     33.7                  trialDataPath, fromRaw=False, reduceChannelIndexes=True)
    77         6        296.0     49.3      0.0              blocksCache[trialDataPath] = dataBlock
    78                                                       #pdb.set_trace()
    79         6        139.0     23.2      0.0              if idx == 0:
    80         2         30.0     15.0      0.0                  masterDataPath = trialDataPath
    81       122      58260.0    477.5      0.0              for chIdx in dataBlock.filter(objects=ChannelIndex):
    82       116      90800.0    782.8      0.0                  chAlreadyThere = masterChanDF.index == chIdx.name
    83       116       7953.0     68.6      0.0                  if not chAlreadyThere.any():
    84        56     866998.0  15482.1      0.2                      masterChanDF.loc[chIdx.name, 'hasUnits'] = len(chIdx.units) > 0
    85        56     236349.0   4220.5      0.0                      masterChanDF.loc[chIdx.name, 'hasAsigs'] = len(chIdx.analogsignals) > 0
    86        56       1432.0     25.6      0.0                      try:
    87        56       1333.0     23.8      0.0                          chIdxNames = chIdx.channel_names
    88        56       1186.0     21.2      0.0                          chIdxIDS = chIdx.channel_ids
    89        56     104286.0   1862.2      0.0                          print('chIdx index = {}'.format(chIdx.index))
    90        56       1587.0     28.3      0.0                          if not len(chIdxIDS):
    91        26        685.0     26.3      0.0                              chIdxIDS = [int(chIdx.index)]
    92        56       1321.0     23.6      0.0                          if not len(chIdxNames):
    93        26        479.0     18.4      0.0                              chIdxNames = [chIdx.name]
    94        56     257552.0   4599.1      0.0                          masterChanDF.loc[chIdx.name, 'index'] = int(chIdx.index)
    95        56     248376.0   4435.3      0.0                          masterChanDF.loc[chIdx.name, 'channel_names'] = chIdxNames
    96        56     247575.0   4421.0      0.0                          masterChanDF.loc[chIdx.name, 'channel_ids'] = chIdxIDS
    97                                                               except Exception:
    98                                                                   traceback.print_exc()
    99       168       5610.0     33.4      0.0                      for annName,  annVal in chIdx.annotations.items():
   100       112     559813.0   4998.3      0.1                          masterChanDF.loc[chIdx.name, annName] = annVal
   101                                                           else:
   102        60       1204.0     20.1      0.0                      if len(chIdx.units) > 0:
   103                                                                   masterChanDF.loc[chAlreadyThere, 'hasUnits'] = True
   104        60       1036.0     17.3      0.0                      if len(chIdx.analogsignals):
   105        60     393013.0   6550.2      0.1                          masterChanDF.loc[chAlreadyThere, 'hasAsigs'] = True
   106        32      44651.0   1395.3      0.0              for unit in (dataBlock.filter(objects=Unit)):
   107        26      16323.0    627.8      0.0                  uAlreadyThere = masterUnitDF.index == unit.name
   108        26       1368.0     52.6      0.0                  if not uAlreadyThere.any():
   109        91       2097.0     23.0      0.0                      for annName, annVal in unit.annotations.items():
   110        65     503132.0   7740.5      0.1                          masterUnitDF.loc[unit.name, annName] = annVal
   111        26        537.0     20.7      0.0                      unitParentChanName = unit.channel_index.name
   112        26      86786.0   3337.9      0.0                      masterUnitDF.loc[unit.name, 'parentChanName'] = unitParentChanName
   113                                                               # chAlreadyThere = masterChanDF.index == unitParentChanName
   114                                                       # dataReader.file.close()
   115                                                   # masterChanDF[masterChanDF['hasUnits']]
   116         8        227.0     28.4      0.0          for idx, trialBasePath in enumerate(trialsToAssemble):
   117                                                       trialDataPath = (
   118         6        136.0     22.7      0.0                  trialBasePath
   119         6        227.0     37.8      0.0                  .format(arguments['analysisName'])
   120         6        225.0     37.5      0.0                  .replace('.nix', '{}.nix'.format(suffix))
   121                                                           )
   122         6       2626.0    437.7      0.0              print('loading trial {}'.format(trialDataPath))
   123         6        126.0     21.0      0.0              if idx == 0:
   124         2         73.0     36.5      0.0                  blocksCache[trialDataPath].name = experimentName + suffix
   125         2         33.0     16.5      0.0                  if applyTimeOffset:
   126                                                               masterTStart = blocksCache[trialDataPath].filter(objects=AnalogSignal)[0].t_start
   127                                                               oldTStop = blocksCache[trialDataPath].filter(objects=AnalogSignal)[0].t_stop
   128                                                       else:
   129         4        123.0     30.8      0.0                  blocksCache[trialDataPath].name = blocksCache[masterDataPath].name
   130         4         83.0     20.8      0.0                  if applyTimeOffset:
   131                                                               tStart = blocksCache[trialDataPath].filter(objects=AnalogSignal)[0].t_start
   132                                                               timeOffset = oldTStop - tStart
   133                                                               blocksCache[trialDataPath] = hf.timeOffsetBlock(
   134                                                                   blocksCache[trialDataPath], timeOffset, masterTStart)
   135                                                               #  [i.times for i in dataBlock.filter(objects=SpikeTrain)]
   136                                                               #  [i.unit.channel_index.name for i in masterBlock.filter(objects=SpikeTrain)]
   137                                                               tStop = dataBlock.filter(objects=AnalogSignal)[0].t_stop
   138                                                       # if suffix == '_binarized':
   139                                                       #     for seg in blocksCache[trialDataPath].segments:
   140                                                       #         seg.spiketrains = []
   141       174     366899.0   2108.6      0.1              for rowIdx, row in masterChanDF.iterrows():
   142       168       4212.0     25.1      0.0                  matchingCh = blocksCache[trialDataPath].filter(
   143       168    2061992.0  12273.8      0.4                      objects=ChannelIndex, name=rowIdx)
   144       168       4036.0     24.0      0.0                  if not len(matchingCh):
   145                                                               '''
   146                                                                   # [ch.index for ch in blocksCache[trialDataPath].filter(objects=ChannelIndex)]
   147                                                                   # if row['index'] is None:
   148                                                                   #     pdb.set_trace()
   149                                                                   #     chIdx = ChannelIndex(
   150                                                                   #         name=rowIdx,
   151                                                                   #         index=np.asarray([0]),
   152                                                                   #         channel_ids=np.asarray([0]),
   153                                                                   #         channel_names=np.asarray([rowIdx]),
   154                                                                   #         file_origin=blocksCache[trialDataPath].channel_indexes[-1].file_origin
   155                                                                   #         )
   156                                                                   # else:
   157                                                               '''
   158                                                               # create it
   159        52      30696.0    590.3      0.0                      print('ch {} not found; creating now'.format(rowIdx))
   160        52       1063.0     20.4      0.0                      chIdx = ChannelIndex(
   161        52        951.0     18.3      0.0                          name=rowIdx,
   162        52      30056.0    578.0      0.0                          index=np.asarray([row['index']]).flatten(),
   163        52      25693.0    494.1      0.0                          channel_ids=np.asarray([row['channel_ids']]).flatten(),
   164        52      19660.0    378.1      0.0                          channel_names=np.asarray([row['channel_names']]).flatten(),
   165        52      24657.0    474.2      0.0                          file_origin=blocksCache[trialDataPath].channel_indexes[-1].file_origin
   166                                                                   )
   167       260     467614.0   1798.5      0.1                      for aN in row.drop(['index', 'channel_names', 'channel_ids']).index:
   168       208      52043.0    250.2      0.0                          chIdx.annotations[aN] = row[aN]
   169        52       1707.0     32.8      0.0                      blocksCache[trialDataPath].channel_indexes.append(chIdx)
   170        52       1236.0     23.8      0.0                      chIdx.block = blocksCache[trialDataPath]
   171                                                               # create blank asigs
   172        52      10723.0    206.2      0.0                      if row['hasAsigs']:
   173        26     931108.0  35811.8      0.2                          dummyAsig = blocksCache[trialDataPath].filter(objects=AnalogSignal)[0].copy()
   174        26       1372.0     52.8      0.0                          dummyAsig.name = 'seg0_' + chIdx.name
   175        26        797.0     30.7      0.0                          dummyAsig.annotations['neo_name'] = dummyAsig.name
   176        26     141457.0   5440.7      0.0                          dummyAsig.magnitude[:] = 0
   177        26        828.0     31.8      0.0                          dummyAsig.channel_index = chIdx
   178        26       1202.0     46.2      0.0                          chIdx.analogsignals.append(dummyAsig)
   179        26       1643.0     63.2      0.0                          blocksCache[trialDataPath].segments[0].analogsignals.append(dummyAsig)
   180        26        740.0     28.5      0.0                          dummyAsig.segment = blocksCache[trialDataPath].segments[0]
   181                                                                   # pdb.set_trace()
   182         6      80648.0  13441.3      0.0              anySpikeTrains = blocksCache[trialDataPath].filter(objects=SpikeTrain)
   183         6        167.0     27.8      0.0              if len(anySpikeTrains):
   184         6       1643.0    273.8      0.0                  wvfUnits = anySpikeTrains[0].waveforms.units
   185         6        754.0    125.7      0.0                  stTimeUnits = anySpikeTrains[0].units
   186                                                       else:
   187                                                           stTimeUnits = pq.s
   188                                                           wvfUnits = pq.uV
   189        84     170694.0   2032.1      0.0              for rowIdx, row in masterUnitDF.iterrows():
   190        78       1995.0     25.6      0.0                  matchingUnit = blocksCache[trialDataPath].filter(
   191        78     983535.0  12609.4      0.2                      objects=Unit, name=rowIdx)
   192        78       2060.0     26.4      0.0                  if not len(matchingUnit):
   193        52      19148.0    368.2      0.0                      parentChanName = row['parentChanName']
   194                                                               # parentChanName = rowIdx
   195                                                               # if parentChanName.endswith('_stim#0'):
   196                                                               #     parentChanName.replace('_stim#0', '')
   197                                                               # if parentChanName.endswith('#0'):
   198                                                               #     parentChanName.replace('#0', '')
   199        52       1368.0     26.3      0.0                      matchingCh = blocksCache[trialDataPath].filter(
   200        52     701517.0  13490.7      0.1                          objects=ChannelIndex, name=parentChanName)
   201                                                               '''
   202                                                                   if not len(matchingCh):
   203                                                                       masterListEntry = masterChanDF.loc[parentChanName, :]
   204                                                                       parentChIdx = ChannelIndex(
   205                                                                           name=parentChanName,
   206                                                                           index=masterListEntry['index'],
   207                                                                           channel_ids=masterListEntry['channel_ids'],
   208                                                                           channel_names=masterListEntry['channel_names'],
   209                                                                           file_origin=blocksCache[trialDataPath].channel_indexes[-1].file_origin
   210                                                                           )
   211                                                                       blocksCache[trialDataPath].channel_indexes.append(parentChIdx)
   212                                                                       parentChIdx.block = blocksCache[trialDataPath]
   213                                                                   else:
   214                                                                       parentChIdx = matchingCh[0]
   215                                                               '''
   216        52       1381.0     26.6      0.0                      parentChIdx = matchingCh[0]
   217        52      26239.0    504.6      0.0                      print('unit {} not found; creating now'.format(rowIdx))
   218        52      16316.0    313.8      0.0                      newUnit = Unit(name=rowIdx)
   219       234      24704.0    105.6      0.0                      for annName in row.index:
   220       182      44557.0    244.8      0.0                          newUnit.annotations[annName] = row[annName]
   221        52       1137.0     21.9      0.0                      newUnit.channel_index = parentChIdx
   222        52       1414.0     27.2      0.0                      parentChIdx.units.append(newUnit)
   223       104       2563.0     24.6      0.0                      for seg in blocksCache[trialDataPath].segments:
   224        52       1098.0     21.1      0.0                          dummyST = SpikeTrain(
   225        52       1097.0     21.1      0.0                              times=[], units=stTimeUnits,
   226        52     332898.0   6401.9      0.1                              t_stop=seg.filter(objects=AnalogSignal)[0].t_stop,
   227        52      11695.0    224.9      0.0                              waveforms=np.array([]).reshape((0, 0, 0)) * wvfUnits,
   228        52      76284.0   1467.0      0.0                              name=seg.name + newUnit.name)
   229        52       1279.0     24.6      0.0                          dummyST.unit = newUnit
   230        52       1051.0     20.2      0.0                          dummyST.segment = seg
   231        52       1197.0     23.0      0.0                          newUnit.spiketrains.append(dummyST)
   232        52       1294.0     24.9      0.0                          seg.spiketrains.append(dummyST)
   233         6        161.0     26.8      0.0              typesNeedRenaming = [SpikeTrain, AnalogSignal, Event]
   234         6        135.0     22.5      0.0              blocksCache[trialDataPath].segments[0].name = 'seg{}_{}'.format(
   235         6        305.0     50.8      0.0                  idx, blocksCache[trialDataPath].name)
   236        24        621.0     25.9      0.0              for objType in typesNeedRenaming:
   237        18     327506.0  18194.8      0.1                  listOfChildren = blocksCache[trialDataPath].filter(objects=objType)
   238        18        650.0     36.1      0.0                  print('{}\n{} objects of type {}'.format(
   239        18      12165.0    675.8      0.0                      trialDataPath, len(listOfChildren), objType
   240                                                           ))
   241       258       8007.0     31.0      0.0                  for child in listOfChildren:
   242       240      14043.0     58.5      0.0                      childBaseName = preproc.childBaseName(child.name, 'seg')
   243       240       9162.0     38.2      0.0                      child.name = 'seg{}_{}'.format(idx, childBaseName)
   244         6     106417.0  17736.2      0.0              blocksCache[trialDataPath].create_relationship()
   245         6     174621.0  29103.5      0.0              blocksCache[trialDataPath] = preproc.purgeNixAnn(blocksCache[trialDataPath])
   246                                                       ########
   247         6        187.0     31.2      0.0              sanityCheck = False
   248         6        142.0     23.7      0.0              if sanityCheck and idx == 2:
   249                                                           doublePath = trialDataPath.replace(suffix, suffix + '_backup')
   250                                                           if os.path.exists(doublePath):
   251                                                               os.remove(doublePath)
   252                                                           print('writing {} ...'.format(doublePath))
   253                                                           for idx, chIdx in enumerate(blocksCache[trialDataPath].channel_indexes):
   254                                                               print('{}: {}, chan_id = {}'.format(
   255                                                                   chIdx.name, chIdx.index, chIdx.channel_ids))
   256                                                           writer = neo.io.NixIO(filename=doublePath)
   257                                                           writer.write_block(blocksCache[trialDataPath], use_obj_names=True)
   258                                                           writer.close()
   259                                                       ############
   260         6        151.0     25.2      0.0              if idx > 0:
   261         4      91767.0  22941.8      0.0                  blocksCache[masterDataPath].merge(blocksCache[trialDataPath])
   262         4        128.0     32.0      0.0                  if applyTimeOffset:
   263                                                               oldTStop = tStop
   264                                                   '''
   265                                                       print([evSeg.events[0].name for evSeg in masterBlock.segments])
   266                                                       print([asig.name for asig in masterBlock.filter(objects=AnalogSignal)])
   267                                                       print([st.name for st in masterBlock.filter(objects=SpikeTrain)])
   268                                                       print([ev.name for ev in masterBlock.filter(objects=Event)])
   269                                                       print([chIdx.name for chIdx in blocksCache[trialDataPath].filter(objects=ChannelIndex)])
   270                                                       print([un.name for un in masterBlock.filter(objects=Unit)])
   271                                                   '''
   272                                                   # blocksCache[masterDataPath].create_relationship()
   273         2       2067.0   1033.5      0.0          if os.path.exists(experimentDataPath):
   274         2    1550960.0 775480.0      0.3              os.remove(experimentDataPath)
   275         2     255947.0 127973.5      0.0          writer = neo.io.NixIO(filename=experimentDataPath)
   276         2       2454.0   1227.0      0.0          print('writing {} ...'.format(experimentDataPath))
   277         2  315493814.0 157746907.0     61.0          writer.write_block(blocksCache[masterDataPath], use_obj_names=True)
   278         2    1498739.0 749369.5      0.3          writer.close()
   279         2         91.0     45.5      0.0          if arguments['commitResults']:
   280                                                       analysisProcessedSubFolder = os.path.join(
   281                                                           processedFolder, arguments['analysisName']
   282                                                           )
   283                                                       if not os.path.exists(analysisProcessedSubFolder):
   284                                                           os.makedirs(analysisProcessedSubFolder, exist_ok=True)
   285                                                       for suffix in suffixList:
   286                                                           experimentDataPath = os.path.join(
   287                                                               scratchFolder, arguments['analysisName'],
   288                                                               assembledName +
   289                                                               suffix + '.nix')
   290                                                           processedOutPath = os.path.join(
   291                                                               analysisProcessedSubFolder, arguments['analysisName'],
   292                                                               assembledName +
   293                                                               suffix + '.nix')
   294                                                           print('copying from:\n{}\ninto\n{}'.format(experimentDataPath, processedOutPath))
   295                                                           shutil.copyfile(experimentDataPath, processedOutPath)
   296         1         16.0     16.0      0.0      return

Timer unit: 1e-07 s

Total time: 1141.13 s
File: C\../../analysis-code/calcAlignedAsigs.py
Function: calcAlignedAsigsWrapped at line 62

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    62                                           @profile
    63                                           def calcAlignedAsigsWrapped():
    64                                               #  source of events
    65         1         28.0     28.0      0.0      if arguments['processAll']:
    66         1         26.0     26.0      0.0          eventPath = experimentDataPath
    67                                               else:
    68                                                   eventPath = analysisDataPath
    69                                           
    70         1       1200.0   1200.0      0.0      print('Loading events from {}'.format(eventPath))
    71         1         26.0     26.0      0.0      eventReader, eventBlock = ns5.blockFromPath(
    72         1  106129384.0 106129384.0      0.9          eventPath, lazy=arguments['lazy'])
    73                                               #  eventBlock = eventReader.read_block(
    74                                               #      block_index=0, lazy=True,
    75                                               #      signal_group_mode='split-all')
    76                                               #  for ev in eventBlock.filter(objects=EventProxy):
    77                                               #      ev.name = '_'.join(ev.name.split('_')[1:])
    78                                           
    79                                               #  source of analogsignals
    80         1         20.0     20.0      0.0      signalBlock = eventBlock
    81                                           
    82                                               windowSize = [
    83         1         13.0     13.0      0.0          i * pq.s
    84         1        509.0    509.0      0.0          for i in rasterOpts['windowSizes'][arguments['window']]]
    85                                           
    86         1         11.0     11.0      0.0      if arguments['processAll']:
    87         1          6.0      6.0      0.0          prefix = assembledName
    88                                               else:
    89                                                   prefix = ns5FileName
    90                                           
    91         1         11.0     11.0      0.0      ns5.getAsigsAlignedToEvents(
    92         1          7.0      7.0      0.0          eventBlock=eventBlock, signalBlock=signalBlock,
    93         1          8.0      8.0      0.0          chansToTrigger=arguments['chanNames'],
    94         1          9.0      9.0      0.0          chanQuery=arguments['chanQuery'],
    95         1          8.0      8.0      0.0          eventName=arguments['eventName'],
    96         1          6.0      6.0      0.0          windowSize=windowSize,
    97         1          7.0      7.0      0.0          minNReps=minNConditionRepetitions,
    98         1          6.0      6.0      0.0          appendToExisting=False,
    99         1          6.0      6.0      0.0          checkReferences=False,
   100         1          8.0      8.0      0.0          verbose=arguments['verbose'],
   101         1          7.0      7.0      0.0          fileName='{}_{}_{}'.format(
   102         1         16.0     16.0      0.0              prefix, arguments['outputBlockName'], arguments['window']),
   103         1 11305126428.0 11305126428.0     99.1          folderPath=alignSubFolder, chunkSize=alignedAsigsChunkSize)
   104                                           
   105         1        788.0    788.0      0.0      print('Finished CalcAlignedAsigs')
   106         1         11.0     11.0      0.0      return

Timer unit: 1e-07 s

Total time: 29.3959 s
File: C\../../analysis-code/calcTrialOutliers.py
Function: findOutliers at line 131

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   131                                           @profile
   132                                           def findOutliers(
   133                                                   mahalDistDF, groupBy=None,
   134                                                   qThresh=None, sdThresh=None, sdThreshInner=None,
   135                                                   devQuantile=None, nDim=1, multiplier=1, twoTailed=False):
   136                                               #
   137         1         20.0     20.0      0.0      if sdThresh is None:
   138         1         12.0     12.0      0.0          if qThresh is None:
   139                                                       qThresh = 1 - 1e-6
   140         1       6096.0   6096.0      0.0          chi2Bounds = chi2.interval(qThresh, nDim)
   141         1         19.0     19.0      0.0          sdThresh = multiplier * chi2Bounds[1]
   142                                               #
   143         1         14.0     14.0      0.0      chiProba = pd.Series(
   144         1    2708997.0 2708997.0      0.9          -np.log(np.squeeze(chi2.pdf(mahalDistDF, nDim))),
   145         1       2262.0   2262.0      0.0          index=mahalDistDF.index)
   146         1       3173.0   3173.0      0.0      chiProbaLim = -np.log(chi2.pdf(sdThresh, nDim))
   147         1         10.0     10.0      0.0      if devQuantile is not None:
   148         1  291219623.0 291219623.0     99.1          deviation = chiProba.groupby(groupBy).quantile(q=devQuantile)
   149                                                   # maxMhDist = mahalDistDF.groupby(groupBy).quantile(q=devQuantile).iloc[:, -1] - sdThresh
   150                                                   # minMhDist = sdThreshInner - mahalDistDF.groupby(groupBy).quantile(q=1-devQuantile).iloc[:, -1]
   151                                               else:
   152                                                   deviation = chiProba.groupby(groupBy).max()
   153                                                   # maxMhDist = mahalDistDF.groupby(groupBy).max().iloc[:, -1] - sdThresh
   154                                                   # minMhDist = sdThreshInner - mahalDistDF.groupby(groupBy).min().iloc[:, -1]
   155                                               #
   156                                               # if twoTailed:
   157                                               #     deviation = pd.concat([maxMhDist, minMhDist], axis='columns').max(axis='columns')
   158                                               #     pdb.set_trace()
   159                                               # else:
   160                                               #     deviation = maxMhDist
   161         1         37.0     37.0      0.0      if isinstance(deviation, pd.Series):
   162         1       6495.0   6495.0      0.0          deviationDF = deviation.to_frame(name='deviation')
   163                                               else:
   164                                                   deviationDF = deviation
   165         1      12733.0  12733.0      0.0      deviationDF['rejectBlock'] = (deviationDF['deviation'] > chiProbaLim)
   166         1          9.0      9.0      0.0      return deviationDF

Total time: 0.0291887 s
File: C\../../analysis-code/calcTrialOutliers.py
Function: calcCovMat at line 168

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   168                                           @profile
   169                                           def calcCovMat(
   170                                                   partition, dataColNames=None,
   171                                                   useEmpiricalCovariance=True,
   172                                                   supportFraction=None, verbose=False):
   173         2       5413.0   2706.5      1.9      dataColMask = partition.columns.isin(dataColNames)
   174         2      18855.0   9427.5      6.5      partitionData = partition.loc[:, dataColMask]
   175                                               # print('partition shape = {}'.format(partitionData.shape))
   176         2         27.0     13.5      0.0      if not useEmpiricalCovariance:
   177                                                   try:
   178                                                       est = MinCovDet(support_fraction=supportFraction)
   179                                                       est.fit(partitionData.values)
   180                                                   except Exception:
   181                                                       traceback.print_exc()
   182                                                       print('\npartition shape = {}\n'.format(partitionData.shape))
   183                                                       est = EmpiricalCovariance()
   184                                                       est.fit(partitionData.values)
   185                                               else:
   186         2        484.0    242.0      0.2          est = EmpiricalCovariance()
   187         2     100743.0  50371.5     34.5          est.fit(partitionData.values)
   188         2         74.0     37.0      0.0      result = pd.DataFrame(
   189         2      22299.0  11149.5      7.6          est.mahalanobis(partitionData.values),
   190         2      25763.0  12881.5      8.8          index=partition.index, columns=['mahalDist'])
   191                                               # print('result shape is {}'.format(result.shape))
   192         2     116495.0  58247.5     39.9      result = pd.concat([result, partition.loc[:, ~dataColMask]], axis=1)
   193         2       1694.0    847.0      0.6      result.name = 'mahalanobisDistance'
   194                                               # pdb.set_trace()
   195                                               # if result['electrode'].iloc[0] == 'foo':
   196                                               #     pdb.set_trace()
   197                                               # print('result type is {}'.format(type(result)))
   198                                               # print(result.T)
   199                                               # print('partition shape = {}'.format(partitionData.shape))
   200         2         40.0     20.0      0.0      return result

Timer unit: 1e-07 s

Total time: 861.083 s
File: C\../../analysis-code/exportForDeepSpine.py
Function: exportForDeepSpineWrapper at line 48

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
    48                                           @profile
    49                                           def exportForDeepSpineWrapper():
    50         1      37149.0  37149.0      0.0      sns.set()
    51         1       5429.0   5429.0      0.0      sns.set_color_codes("dark")
    52         1       3683.0   3683.0      0.0      sns.set_context("talk")
    53         1       9843.0   9843.0      0.0      sns.set_style("whitegrid")
    54                                               #
    55         1         77.0     77.0      0.0      analysisSubFolder = os.path.join(
    56         1        553.0    553.0      0.0          scratchFolder, arguments['analysisName']
    57                                                   )
    58         1         62.0     62.0      0.0      alignSubFolder = os.path.join(
    59         1        418.0    418.0      0.0          analysisSubFolder, arguments['alignFolderName']
    60                                                   )
    61         1        398.0    398.0      0.0      calcSubFolder = os.path.join(alignSubFolder, 'dataframes')
    62         1       1637.0   1637.0      0.0      if not os.path.exists(calcSubFolder):
    63                                                   os.makedirs(calcSubFolder, exist_ok=True)
    64                                           
    65         1         70.0     70.0      0.0      if arguments['processAll']:
    66         1         59.0     59.0      0.0          prefix = assembledName
    67                                               else:
    68                                                   prefix = ns5FileName
    69         1         65.0     65.0      0.0      alignedAsigsKWargs['dataQuery'] = ash.processAlignQueryArgs(
    70         1        213.0    213.0      0.0          namedQueries, **arguments)
    71                                               alignedAsigsKWargs['unitNames'], alignedAsigsKWargs['unitQuery'] = (
    72         1         67.0     67.0      0.0          ash.processUnitQueryArgs(
    73         1        231.0    231.0      0.0              namedQueries, analysisSubFolder, **arguments))
    74         1         64.0     64.0      0.0      outlierTrialNames = ash.processOutlierTrials(
    75         1     225872.0 225872.0      0.0          calcSubFolder, prefix, **arguments)
    76                                           
    77         1         37.0     37.0      0.0      if arguments['window'] == 'XS':
    78         1         20.0     20.0      0.0          cropWindow = (-100e-3, 400e-3)
    79                                               elif arguments['window'] == 'XSPre':
    80                                                   cropWindow = (-600e-3, -100e-3)
    81                                           
    82         1         25.0     25.0      0.0      alignedAsigsKWargs.update(dict(
    83         1         19.0     19.0      0.0          duplicateControlsByProgram=False,
    84         1         19.0     19.0      0.0          makeControlProgram=False,
    85         1         19.0     19.0      0.0          metaDataToCategories=False,
    86         1         19.0     19.0      0.0          removeFuzzyName=False,
    87         1         18.0     18.0      0.0          decimate=1,
    88         1         19.0     19.0      0.0          windowSize=cropWindow,
    89         1         46.0     46.0      0.0          transposeToColumns='feature', concatOn='columns',))
    90                                               #
    91         1         32.0     32.0      0.0      triggeredPath = os.path.join(
    92         1         19.0     19.0      0.0          alignSubFolder,
    93         1         20.0     20.0      0.0          prefix + '_{}_{}.nix'.format(
    94         1        219.0    219.0      0.0              arguments['inputBlockName'], arguments['window']))
    95         1         20.0     20.0      0.0      outputPath = os.path.join(
    96         1         19.0     19.0      0.0          alignSubFolder,
    97         1         19.0     19.0      0.0          prefix + '_{}_{}_export.h5'.format(
    98         1        144.0    144.0      0.0              arguments['inputBlockName'], arguments['window']))
    99         1        583.0    583.0      0.0      print('loading {}'.format(triggeredPath))
   100                                           
   101         1         28.0     28.0      0.0      dataReader, dataBlock = ns5.blockFromPath(
   102         1   75969138.0 75969138.0      0.9          triggeredPath, lazy=arguments['lazy'])
   103         1         40.0     40.0      0.0      asigWide = ns5.alignedAsigsToDF(
   104         1  206351357.0 206351357.0      2.4          dataBlock, **alignedAsigsKWargs)
   105                                               # asigWide is a dataframe
   106         1    6104194.0 6104194.0      0.1      metaData = asigWide.index.to_frame()
   107         1    1504241.0 1504241.0      0.0      elecNames = metaData['electrode'].unique()
   108                                           
   109                                               # elecRegex = r'([\-]?[\S\s]*\d)([\+]?[\S\s]*\d)'
   110                                               # elecRegex = r'((?:\-|\+)(?:(?:rostral|caudal)\S_\S\S\S)*)*'
   111                                           
   112         1         34.0     34.0      0.0      elecRegex = r'((?:\-|\+)(?:(?:rostral|caudal)\S_\S\S\S)*)'
   113         1         19.0     19.0      0.0      chanRegex = r'((?:rostral|caudal)\S_\S\S\S)'
   114         1         20.0     20.0      0.0      elecChanNames = []
   115         1         19.0     19.0      0.0      stimConfigLookup = {}
   116        14        332.0     23.7      0.0      for comboName in elecNames:
   117        13      10082.0    775.5      0.0          matches = re.findall(elecRegex, comboName)
   118        13        252.0     19.4      0.0          if matches:
   119        13       2906.0    223.5      0.0              print(comboName)
   120        13        290.0     22.3      0.0              thisLookup = {'cathodes': [], 'anodes': []}
   121        26        507.0     19.5      0.0              for matchGroup in matches:
   122        13       2371.0    182.4      0.0                  print('\t' + matchGroup)
   123        13        264.0     20.3      0.0                  if len(matchGroup):
   124        13       6855.0    527.3      0.0                      theseChanNames = re.findall(chanRegex, matchGroup)
   125        13        253.0     19.5      0.0                      if theseChanNames:
   126        26        501.0     19.3      0.0                          for chanName in theseChanNames:
   127        13        274.0     21.1      0.0                              if chanName not in elecChanNames:
   128        13        267.0     20.5      0.0                                  elecChanNames.append(chanName)
   129        13        257.0     19.8      0.0                          if '-' in matchGroup:
   130        26        506.0     19.5      0.0                              for chanName in theseChanNames:
   131        13        262.0     20.2      0.0                                  if chanName not in thisLookup['cathodes']:
   132        13        265.0     20.4      0.0                                      thisLookup['cathodes'].append(chanName)
   133        13        254.0     19.5      0.0                          if '+' in matchGroup:
   134                                                                       for chanName in theseChanNames:
   135                                                                           if chanName not in thisLookup['anodes']:
   136                                                                               thisLookup['anodes'].append(chanName)
   137        13        270.0     20.8      0.0              stimConfigLookup[comboName] = thisLookup
   138                                           
   139         1         36.0     36.0      0.0      eesColumns = pd.MultiIndex.from_tuples(
   140         1         85.0     85.0      0.0          [(eCN, 'amplitude') for eCN in sorted(elecChanNames)],
   141         1      18882.0  18882.0      0.0          names=['object', 'property']
   142                                                   )
   143                                               #
   144         1    1745722.0 1745722.0      0.0      trialIndex = pd.Index(np.unique(metaData['bin']))
   145         1         49.0     49.0      0.0      trialColumns = pd.MultiIndex.from_tuples(
   146                                                   [
   147         1         21.0     21.0      0.0              ('hip_flexion_r', 'angle'), ('knee_angle_r', 'angle'),
   148         1         23.0     23.0      0.0              ('hip_flexion_l', 'angle'), ('knee_angle_l', 'angle'),
   149         1      17693.0  17693.0      0.0          ], names=['object', 'property'])
   150                                               #
   151                                               # manualPeriod = 0.01
   152                                               # manualStimTimes = np.arange(0, 0.3 + manualPeriod, manualPeriod)
   153                                               # manualEESWaveform = trialIndex.isin(manualStimTimes)
   154                                               # print(metaData.reset_index(drop=True))
   155                                               # print(metaData['electrode'])
   156         1         31.0     31.0      0.0      nullKinematics = pd.DataFrame(
   157         1       2412.0   2412.0      0.0          0, index=trialIndex, columns=trialColumns)
   158         1         23.0     23.0      0.0      kinKey = '/sling/kinematics'
   159         1     159523.0 159523.0      0.0      with pd.HDFStore(outputPath) as store:
   160         1     430343.0 430343.0      0.0          nullKinematics.to_hdf(store, kinKey)
   161         1         82.0     82.0      0.0      eesIdx = 0
   162                                           
   163       716   14382435.0  20087.2      0.2      for stimName, stimGroup in asigWide.groupby(['electrode', 'RateInHz', 'nominalCurrent']):
   164       715   18168391.0  25410.3      0.2          if stimGroup.groupby(['segment', 't']).ngroups < 5:
   165                                                       continue
   166       715     486861.0    680.9      0.0          print(stimName)
   167      7865  133274378.0  16945.2      1.5          for trialIdx, (trialName, trialGroup) in enumerate(stimGroup.groupby(['segment', 't'])):
   168      7150     460506.0     64.4      0.0              stimKey = '/sling/sheep/spindle_0/biophysical/ees_{:0>3}/stim'.format(eesIdx)
   169      7150     398114.0     55.7      0.0              eesPeriod = stimName[1] ** -1
   170      7150     673560.0     94.2      0.0              stimTimes = np.arange(0, 0.3, eesPeriod)
   171      7150    2537494.0    354.9      0.0              EESWaveform = np.zeros_like(trialIndex)
   172                                                       # TODO replace this with the hf.findClosestTimes implementation
   173      7150     228707.0     32.0      0.0              if not arguments['noStim']:
   174    124410    3531370.0     28.4      0.0                  for stimTime in stimTimes:
   175    117260  366316203.0   3124.0      4.3                      closestIndexTime = np.argmin(np.abs((trialIndex - stimTime)))
   176    117260    4012883.0     34.2      0.0                      EESWaveform[closestIndexTime] = 1
   177      7150     189475.0     26.5      0.0              eesIdx += 1
   178      7150   19249591.0   2692.3      0.2              theseResults = pd.DataFrame(0, index=trialIndex, columns=eesColumns)
   179     14300     537444.0     37.6      0.0              for cathodeName in stimConfigLookup[stimName[0]]['cathodes']:
   180      7150   99211297.0  13875.7      1.2                  theseResults.loc[:, (cathodeName, 'amplitude')] = EESWaveform * stimName[2] / len(stimConfigLookup[stimName[0]]['cathodes'])
   181      7150     232525.0     32.5      0.0              for anodeName in stimConfigLookup[stimName[0]]['anodes']:
   182                                                           theseResults.loc[:, (anodeName, 'amplitude')] = EESWaveform * stimName[2] * (-1) / len(stimConfigLookup[stimName[0]]['anodes'])
   183    100100    6600730.0     65.9      0.1              for cName, lag in trialGroup.columns:
   184     92950    2591912.0     27.9      0.0                  if 'EmgEnv' in cName:
   185     92950    3355954.0     36.1      0.0                      mName = cName.split('EmgEnv')[0]
   186     92950 3325091925.0  35772.9     38.6                      theseResults.loc[:, (mName, 'emg_env')] = trialGroup[cName].to_numpy()
   187                                                           elif 'Emg' in cName:
   188                                                               mName = cName.split('Emg')[0]
   189                                                               theseResults.loc[:, (mName, 'emg')] = trialGroup[cName].to_numpy()
   190                                                           elif ('caudal' in cName) or ('rostral' in cName):
   191                                                               lfpName = cName[:-4]
   192                                                               theseResults.loc[:, (lfpName, 'lfp')] = trialGroup[cName].to_numpy()
   193                                                           elif ('Acc' in cName):
   194                                                               nameParts = cName.split('Acc')
   195                                                               mName = nameParts[0]
   196                                                               theseResults.loc[:, (mName, 'acc_{}'.format(nameParts[1][0].lower()))] = trialGroup[cName].to_numpy()
   197      7150  883140313.0 123516.1     10.3              with pd.HDFStore(outputPath) as store:
   198      7150 3288677203.0 459954.9     38.2                  theseResults.to_hdf(store, stimKey)
   199                                                           thisMetadata = {
   200      7150     294185.0     41.1      0.0                      'globalIdx': eesIdx, 'combinationIdx': trialIdx,
   201      7150     214843.0     30.0      0.0                      'electrode': stimName[0], 'RateInHz': stimName[1],
   202      7150     251155.0     35.1      0.0                      'amplitude': stimName[2]}
   203      7150     248370.0     34.7      0.0                  if arguments['maskOutlierBlocks']:
   204      7150   17881943.0   2501.0      0.2                      thisMetadata['outlierTrial'] = outlierTrialNames.loc[trialName]
   205      7150  125972300.0  17618.5      1.5                  store.get_storer(stimKey).attrs.metadata = thisMetadata
   206                                           
   207         1         58.0     58.0      0.0      if arguments['lazy']:
   208                                                   dataReader.file.close()
   209         1         29.0     29.0      0.0      return

